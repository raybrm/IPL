{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ipl I317B Sécurité : labos\n",
    "## Semaine 1 : introduction et outils python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assurez vous que les paquets suivant soient bien installé :\n",
    "\n",
    "`pip3 install --user requests bs4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le packet requests nous permet de faire des requêtes web facilement, par exemple :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ipl_req = requests.get(\"http://www.vinci.be/fr-be/ipl/Pages/Accueil.aspx\")`\n",
    "\n",
    "`if ipl_req.ok:\n",
    "    ipl_html = ipl_req.text\n",
    "else:\n",
    "    print(ipl_req.status_code)\n",
    "    print(ipl_req.reason)`\n",
    "\n",
    "(Doc requests : http://docs.python-requests.org/en/master/ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite lire le code source de la page en affichant `ipl_html`. Parser cela avec des split ou des regex deviendrait vite infernal, c'est là qu'intervient la librairie BeautifulSoup qui nous permet de parcourir beaucoup plus simplement le dom avec les fonctions `find` et `find_all`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`soup = BeautifulSoup(ipl_html)`\n",
    "\n",
    "`soup.find(\"title\").text  # pour récupérer le contenu de la balise <title>`\n",
    "\n",
    "La fonction `find` et la fonction `find_all` vous renverrons un object de type `tag` (balise) sur lequel vous pouvez faire :\n",
    "  * `find()` et `find_all()`\n",
    "  * `get_text()` pour récupérer tout le contenu textuel de la balise\n",
    "  * `[\"nom de l'attribut\"]` pour récupérer un attribut en particulier (exemple: `tag['href']`)\n",
    "  * ...\n",
    "\n",
    "( Doc BeautifulSoup4 : https://www.crummy.com/software/BeautifulSoup/bs4/doc/ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1:\n",
    "Récupérez le contenue de la page suivante et affichez son titre proprement (sans les retours à la ligne) : http://www.vinci.be/fr-be/ipl/Pages/Accueil.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul-Lambin Accueil\n",
      "Paul-Lambin Accueil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file D:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "req = requests.get(\"http://www.vinci.be/fr-be/ipl/Pages/Accueil.aspx\")\n",
    "soup = BeautifulSoup(req.text)\n",
    "\n",
    "titre = soup.find(\"title\").get_text()\n",
    "\n",
    "# print(titre) <= le html de la page est moche et ça se print mal\n",
    "\n",
    "print(\" \".join(titre.split()))\n",
    "# ou\n",
    "import re\n",
    "print(re.sub('\\s+',' ', titre).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de faire des requêtes beaucoup plus poussée en ajoutant des arguments correspondant aux attributs des balises que nous cherchons, par exemple pour trouver les balises `<div class=\"footer\"></div>` :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`soup.find_all(\"div\", class_=\"footer\")  # NB: class est un mot clé réservé en python, d'où l'ajout du \"_\" dans BeautifulSoup`\n",
    "\n",
    "Ou encore pour trouver tous les liens vers la page facebook de l'ipl :\n",
    "\n",
    "`soup.find_all(\"a\", href=\"https://www.facebook.com/InstitutPaulLambim\")`\n",
    "\n",
    "BeautifoulSoup acceptes également les regex compilée en argument, il est donc possible de récupérer la liste des url qui ne sont pas du domaines de \"vinci.be\" :\n",
    "\n",
    "`not_vinci = re.compile(\"http(s?)://(?!www.vinci.be/)*\")`\n",
    "\n",
    "`soup.find_all(\"a\", href=not_vinci)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2:\n",
    "Depuis le site du cert Français présenté au cours théorique https://www.cert.ssi.gouv.fr/alerte/actives/ , récupérez la liste des alertes de sécurités récentes et affichez leurs titres et le lien vers le document pdf les résumants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnérabilité activement exploitée dans le framework STRUTS 2\n",
      "\tlink : https://www.cert.ssi.gouv.fr/pdf/CERTFR-2018-ALE-010.pdf\n",
      "\n",
      "Campagne de messages électroniques non sollicités de type Locky Locker\n",
      "\tlink : https://www.cert.ssi.gouv.fr/pdf/CERTFR-2018-ALE-008.pdf\n",
      "\n",
      "Multiples vulnérabilités dans  S/MIME et OpenPGP\n",
      "\tlink : https://www.cert.ssi.gouv.fr/pdf/CERTFR-2018-ALE-007.pdf\n",
      "\n",
      "Multiples vulnérabilités de fuite d’informations dans des processeurs\n",
      "\tlink : https://www.cert.ssi.gouv.fr/pdf/CERTFR-2018-ALE-001.pdf\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file D:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(\"https://www.cert.ssi.gouv.fr/alerte/actives/\")\n",
    "soup = BeautifulSoup(req.content)\n",
    "\n",
    "for article in soup.find_all(\"article\", class_=\"cert-alert\"):\n",
    "    print(article.find(\"h3\").text)\n",
    "    print(\"\\tlink : https://www.cert.ssi.gouv.fr\" + article.find(\"a\", href=re.compile(\".*.pdf\"))[\"href\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3:\n",
    "La lib requests permet également d'effectuer de requête POST. Pour tester cette fonctionnalitée, créez un \"requestbin\" sur le site http://requestbin.net/ puis utilisez requests pour poster des données.\n",
    "\n",
    "Voir : http://docs.python-requests.org/en/master/user/quickstart/#make-a-request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "requestbin_link = 'http://requestbin.net/r/12v4jh31'\n",
    "\n",
    "r = requests.post(requestbin_link, data={\"some\": \"data\"})\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous avez certainement constaté sur requestbin que requests utilise un User-Agent explicite \"je suis un lib python pour faire des requêtes\". Documentez-vous sur la manière de changer celui-ci et remplacez le dans votre précédente requête par quelque chose de plus discret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB\n",
    "\n",
    "En rafraichissant la page sur requestbin, vous pouvez consulter les requêtes effectuées dessus, c'est tout l'intérêt du service. Juste pour le lulz, je vais la parser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file D:\\Anaconda\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "def get_previous_requests():\n",
    "    r = requests.get(requestbin_link + \"?inspect\")\n",
    "    soup = BeautifulSoup(r.text)\n",
    "\n",
    "    for rb_request in soup.find_all(\"div\", class_=\"message-wrapper\"):\n",
    "        # ils affichent un \"XX ago\" mais stockent le vrai timestamp dans la balise\n",
    "        timestamp = rb_request.find(\"span\", title=re.compile(\"\\d{4}(-\\d{2}){2} (\\d{2}:){2}\\d{2}.\\d{6}\"))\n",
    "        print(\"date : \" + timestamp[\"title\"] + \" (\" + timestamp.text.strip() + \")\")\n",
    "\n",
    "        print(\"type : \" + rb_request.find(\"span\", class_=\"method\").text)\n",
    "\n",
    "        for header in rb_request.find_all(\"p\", class_=\"keypair\"):\n",
    "            if \"User-Agent\" in header.text:  # filtrons un peu pour éviter trop de bruit dans le pad ...\n",
    "                print(header.text)\n",
    "        print()\n",
    "\n",
    "get_previous_requests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(requestbin_link,\n",
    "              data={\"some\": \"data\"},\n",
    "              headers={'user-agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0'}\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date : 2018-09-26 02:38:12.758087 (0s ago)\n",
      "type : POST\n",
      "User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0\n",
      "\n",
      "date : 2018-09-26 02:38:11.986941 (1s ago)\n",
      "type : POST\n",
      "User-Agent: python-requests/2.19.1\n",
      "\n",
      "date : 2018-09-25 21:03:43.946273 (5h ago)\n",
      "type : POST\n",
      "User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0\n",
      "\n",
      "date : 2018-09-25 21:03:34.262733 (5h ago)\n",
      "type : POST\n",
      "User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0\n",
      "\n",
      "date : 2018-09-25 21:03:31.121826 (5h ago)\n",
      "type : POST\n",
      "User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0\n",
      "\n",
      "date : 2018-09-25 20:49:10.025058 (5h ago)\n",
      "type : POST\n",
      "User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0\n",
      "\n",
      "date : 2018-09-25 20:46:22.666391 (5h ago)\n",
      "type : POST\n",
      "User-Agent: python-requests/2.19.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tant qu'à faire, vérifions la nouvelle requête\n",
    "get_previous_requests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4:\n",
    "\n",
    "Utilisez requests et BeautifulSoup pour automatiser une requête google. Pour ce faire, il vous est demandé de récupérer tous les input caché dans le formulaire de recherche de google, d'y ajouter vos termes de recherche et d'effectuer la requête correspondante avec requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-70f2390725f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://www.google.com\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "r = session.get(\"https://www.google.com\")\n",
    "soup = BeautifulSoup(r.content)\n",
    "\n",
    "form = soup.find(\"form\")\n",
    "# print(form.prettify())\n",
    "\n",
    "inputs = {}\n",
    "for i in form.find_all(\"input\"):\n",
    "    if i[\"name\"].startswith(\"btn\"):\n",
    "        # on passe les boutons (\"J'ai de la chance\" et \"Recherche Google\")\n",
    "        continue\n",
    "    inputs[i[\"name\"]] = i.get(\"value\", \"\")  # {}.get(key, default_value)\n",
    "\n",
    "inputs[\"q\"] = \"Donatien Grolaux\".replace(\" \", \"%20\")\n",
    "\n",
    "# hum ... zut, google sert mal mon exemple car c'est un GET et pas un POST.\n",
    "# Il faut donc reconstruire l'url avec les arguments dedans ...\n",
    "string_input = \"&\".join(\n",
    "    [k + \"=\" + v for k, v in inputs.items()]\n",
    ")\n",
    "\n",
    "print(\"https://www.google.com/search?\" + string_input)\n",
    "\n",
    "r = session.get(\"https://www.google.com/search?\" + string_input,\n",
    "                  headers={'user-agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:62.0) Gecko/20100101 Firefox/62.0'}\n",
    "                 )\n",
    "\n",
    "# affichons quelques lignes de résultats :\n",
    "soup_res = BeautifulSoup(r.content)\n",
    "for res in soup_res.find_all(\"h3\"):\n",
    "    print(\"* \" + res.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
